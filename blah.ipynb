{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool, load_tools\n",
    "from langchain_community.tools.file_management.read import ReadFileTool\n",
    "from langchain_community.tools.file_management.write import WriteFileTool\n",
    "from langchain_community.tools.semanticscholar.tool import SemanticScholarQueryRun\n",
    "from langchain_community.utilities import ArxivAPIWrapper, GoogleSerperAPIWrapper\n",
    "from langchain_community.chat_message_histories import FileChatMessageHistory\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "from langchain_experimental.autonomous_agents import AutoGPT\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.llms import Ollama\n",
    "import faiss\n",
    "\n",
    "load_dotenv('.env')\n",
    "\n",
    "# https://github.com/langchain-ai/langchain/blob/master/cookbook/autogpt/autogpt.ipynb\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "\n",
    "embedding_size = 1536\n",
    "index = faiss.IndexFlatL2(embedding_size)\n",
    "vectorstore = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {})\n",
    "\n",
    "# Step 2: Create a Slack Tool\n",
    "from slack_sdk import WebClient\n",
    "from slack_sdk.errors import SlackApiError\n",
    "import os\n",
    "\n",
    "client = WebClient(token=os.environ.get(\"SLACK_BOT_TOKEN\"))\n",
    "\n",
    "@tool\n",
    "def post_message(message) -> str:\n",
    "    \"\"\"Posts message to Slack\"\"\"\n",
    "    try:\n",
    "        response = client.chat_postMessage(channel=\"#backend\", text=message)\n",
    "        return f\"Message posted to #backend\"\n",
    "    except SlackApiError as e:\n",
    "        return f\"Error posting message: {e.response['error']}\"\n",
    "\n",
    "# Step 3: Integrate Slack Tool with AutoGPT\n",
    "# Add the SlackTool to your tools list\n",
    "arxiv = ArxivAPIWrapper()\n",
    "search = GoogleSerperAPIWrapper()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"arxiv\",\n",
    "        func=arxiv.run,\n",
    "        description=\"Useful for when you need to find specific research papers. You should be specific with authors, titles, or technical terms.\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events. You should ask targeted questions\",\n",
    "    ),\n",
    "    SemanticScholarQueryRun(),\n",
    "    WriteFileTool(),\n",
    "    ReadFileTool(),\n",
    "    Tool(\n",
    "        name=\"post_message\",\n",
    "        func=post_message,\n",
    "        description=\"Posts message to Slack\"\n",
    "    )\n",
    "]\n",
    "\n",
    "agent = AutoGPT.from_llm_and_tools(\n",
    "    ai_name=\"SlackBotGPT\",\n",
    "    ai_role=\"Assistant\",\n",
    "    tools=tools,\n",
    "    llm=ChatOpenAI(temperature=0.5, model_name=\"gpt-3.5-turbo\"),\n",
    "    # llm = Ollama(temperature=0.5, model=\"mistral\"),\n",
    "    memory=vectorstore.as_retriever(),\n",
    "    human_in_the_loop=True, # Set to True if you want to add feedback at each step.\n",
    "    chat_history_memory=FileChatMessageHistory(\"slack_chat_history.txt\"),\n",
    ")\n",
    "# Set verbose to be true\n",
    "agent.chain.verbose = True\n",
    "\n",
    "# Step 4: Update AutoGPT Workflow\n",
    "# Example of how you might modify the agent.run() method\n",
    "agent.run([\n",
    "    \"Find me 10 resources that explain what differential privacy is, how we train DP machine learning models, why DP models sometimes don't converge, and solutions to make differentially private models converge better. Summarize your findings for each source, quote from your sources, and also link to your sources. Post the summary to the Slack channel.\",\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
